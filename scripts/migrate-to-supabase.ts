/**
 * Comprehensive Migration Script: JSON to Supabase Database
 * This script migrates all existing JSON data to the new Supabase schema
 */

import { createClient } from '@supabase/supabase-js';
import fs from 'fs/promises';
import path from 'path';
import { config } from 'dotenv';

// Load environment variables
config({ path: '.env.local' });

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!,
  {
    auth: {
      autoRefreshToken: false,
      persistSession: false
    }
  }
);

interface MigrationStats {
  employees: number;
  attendance: number;
  payroll: number;
  vehicles: number;
  countries: number;
  holidays: number;
  errors: string[];
}

class DataMigrator {
  private stats: MigrationStats = {
    employees: 0,
    attendance: 0,
    payroll: 0,
    vehicles: 0,
    countries: 0,
    holidays: 0,
    errors: []
  };

  async runFullMigration() {
    console.log('üöÄ Starting comprehensive data migration...');
    console.log('='.repeat(60));

    try {
      // Step 1: Backup existing data
      await this.createBackup();

      // Step 2: Migrate reference data first
      await this.migrateCountries();
      await this.migrateHolidays();

      // Step 3: Migrate core business data
      await this.migrateEmployees();
      await this.migrateAttendanceData();
      await this.migratePayrollData();
      await this.migrateVehicles();

      // Step 4: Migrate transactional data
      await this.migratePurchaseData();
      await this.migrateSalesData();

      // Step 5: Generate migration report
      this.generateReport();

    } catch (error) {
      console.error('‚ùå Migration failed:', error);
      this.stats.errors.push(`Migration failed: ${error}`);
      throw error;
    }
  }

  private async createBackup() {
    console.log('üì¶ Creating backup of existing JSON files...');
    
    const backupDir = path.join(process.cwd(), 'database', 'backup', new Date().toISOString().split('T')[0]);
    
    try {
      await fs.mkdir(backupDir, { recursive: true });
      
      // Copy all JSON files to backup
      const sourceDirs = [
        'database/hr',
        'database/purchase',
        'database/vehicles'
      ];

      for (const sourceDir of sourceDirs) {
        const sourcePath = path.join(process.cwd(), sourceDir);
        const targetPath = path.join(backupDir, sourceDir.split('/').pop()!);
        
        try {
          await this.copyDirectory(sourcePath, targetPath);
          console.log(`‚úÖ Backed up ${sourceDir}`);
        } catch (error) {
          console.log(`‚ö†Ô∏è  Could not backup ${sourceDir}: ${error}`);
        }
      }
      
      console.log(`‚úÖ Backup completed in: ${backupDir}`);
    } catch (error) {
      console.warn('‚ö†Ô∏è  Backup creation failed:', error);
    }
  }

  private async copyDirectory(source: string, target: string) {
    try {
      await fs.mkdir(target, { recursive: true });
      const files = await fs.readdir(source, { withFileTypes: true });

      for (const file of files) {
        const sourcePath = path.join(source, file.name);
        const targetPath = path.join(target, file.name);

        if (file.isDirectory()) {
          await this.copyDirectory(sourcePath, targetPath);
        } else {
          await fs.copyFile(sourcePath, targetPath);
        }
      }
    } catch (error) {
      console.warn(`Could not copy ${source}:`, error);
    }
  }

  private async migrateCountries() {
    console.log('üåç Migrating countries data...');
    
    try {
      const countriesPath = path.join(process.cwd(), 'database/hr/countries.json');
      const data = JSON.parse(await fs.readFile(countriesPath, 'utf-8'));
      
      for (const country of data) {
        const { error } = await supabase
          .from('countries')
          .upsert({
            name: country.name,
            code: country.code
          }, {
            onConflict: 'code'
          });

        if (error) {
          this.stats.errors.push(`Country migration error: ${error.message}`);
        } else {
          this.stats.countries++;
        }
      }
      
      console.log(`‚úÖ Migrated ${this.stats.countries} countries`);
    } catch (error) {
      console.error('‚ùå Countries migration failed:', error);
      this.stats.errors.push(`Countries migration failed: ${error}`);
    }
  }

  private async migrateHolidays() {
    console.log('üéâ Migrating holidays data...');
    
    try {
      const holidaysDir = path.join(process.cwd(), 'database/hr/holidays');
      const files = await fs.readdir(holidaysDir);
      
      for (const file of files) {
        if (file.endsWith('.json')) {
          const filePath = path.join(holidaysDir, file);
          const data = JSON.parse(await fs.readFile(filePath, 'utf-8'));
          
          // Handle both array and object formats
          const holidays = Array.isArray(data) ? data : [data];
          
          for (const holiday of holidays) {
            const { error } = await supabase
              .from('holidays')
              .insert({
                name: holiday.name,
                date: holiday.date,
                type: holiday.type || 'public',
                description: holiday.description,
                is_recurring: holiday.is_recurring || false
              });

            if (error) {
              this.stats.errors.push(`Holiday migration error: ${error.message}`);
            } else {
              this.stats.holidays++;
            }
          }
        }
      }
      
      console.log(`‚úÖ Migrated ${this.stats.holidays} holidays`);
    } catch (error) {
      console.error('‚ùå Holidays migration failed:', error);
      this.stats.errors.push(`Holidays migration failed: ${error}`);
    }
  }

  private async migrateEmployees() {
    console.log('üë• Migrating employee data...');
    
    try {
      const employeesDir = path.join(process.cwd(), 'database/hr/employees');
      const files = await fs.readdir(employeesDir);
      
      for (const file of files) {
        if (file.endsWith('.json')) {
          const filePath = path.join(employeesDir, file);
          const employee = JSON.parse(await fs.readFile(filePath, 'utf-8'));
          
          // Get or create department
          let departmentId = null;
          if (employee.department) {
            const { data: dept } = await supabase
              .from('departments')
              .select('id')
              .eq('name', employee.department)
              .single();
            
            departmentId = dept?.id;
          }

          const { error } = await supabase
            .from('employees')
            .insert({
              employee_id: employee.employee_id,
              full_name: employee.full_name || employee.name,
              email: employee.email,
              phone: employee.phone,
              department_id: departmentId,
              position: employee.position,
              hire_date: employee.hire_date,
              salary: employee.salary ? parseFloat(employee.salary) : null,
              nationality: employee.nationality,
              address: employee.address,
              emergency_contact: employee.emergency_contact ? JSON.stringify(employee.emergency_contact) : null,
              documents: employee.documents ? JSON.stringify(employee.documents) : null,
              status: employee.status || 'active'
            });

          if (error) {
            this.stats.errors.push(`Employee migration error for ${file}: ${error.message}`);
          } else {
            this.stats.employees++;
          }
        }
      }
      
      console.log(`‚úÖ Migrated ${this.stats.employees} employees`);
    } catch (error) {
      console.error('‚ùå Employee migration failed:', error);
      this.stats.errors.push(`Employee migration failed: ${error}`);
    }
  }

  private async migrateAttendanceData() {
    console.log('üìÖ Migrating attendance data...');
    
    try {
      const attendanceDir = path.join(process.cwd(), 'database/hr/attendance_data');
      const years = await fs.readdir(attendanceDir);
      
      for (const year of years) {
        const yearDir = path.join(attendanceDir, year);
        const months = await fs.readdir(yearDir);
        
        for (const month of months) {
          const monthDir = path.join(yearDir, month);
          const files = await fs.readdir(monthDir);
          
          for (const file of files) {
            if (file.endsWith('.json')) {
              const filePath = path.join(monthDir, file);
              const attendanceData = JSON.parse(await fs.readFile(filePath, 'utf-8'));
              
              // Get employee ID from database
              const employeeId = file.replace('.json', '');
              const { data: employee } = await supabase
                .from('employees')
                .select('id')
                .eq('employee_id', employeeId)
                .single();

              if (!employee) {
                this.stats.errors.push(`Employee not found for attendance: ${employeeId}`);
                continue;
              }

              // Handle both array and object formats
              const records = Array.isArray(attendanceData) ? attendanceData : [attendanceData];
              
              for (const record of records) {
                const { error } = await supabase
                  .from('attendance_records')
                  .insert({
                    employee_id: employee.id,
                    date: record.date,
                    check_in: record.check_in,
                    check_out: record.check_out,
                    break_start: record.break_start,
                    break_end: record.break_end,
                    hours_worked: record.hours_worked ? parseFloat(record.hours_worked) : null,
                    overtime_hours: record.overtime_hours ? parseFloat(record.overtime_hours) : 0,
                    status: record.status || 'present',
                    notes: record.notes
                  });

                if (error && !error.message.includes('duplicate')) {
                  this.stats.errors.push(`Attendance migration error: ${error.message}`);
                } else if (!error) {
                  this.stats.attendance++;
                }
              }
            }
          }
        }
      }
      
      console.log(`‚úÖ Migrated ${this.stats.attendance} attendance records`);
    } catch (error) {
      console.error('‚ùå Attendance migration failed:', error);
      this.stats.errors.push(`Attendance migration failed: ${error}`);
    }
  }

  private async migratePayrollData() {
    console.log('üí∞ Migrating payroll data...');
    
    try {
      const payrollDir = path.join(process.cwd(), 'database/hr/payroll_data');
      const years = await fs.readdir(payrollDir);
      
      for (const year of years) {
        const yearDir = path.join(payrollDir, year);
        const months = await fs.readdir(yearDir);
        
        for (const month of months) {
          const monthDir = path.join(yearDir, month);
          const files = await fs.readdir(monthDir);
          
          for (const file of files) {
            if (file.endsWith('.json')) {
              const filePath = path.join(monthDir, file);
              const payrollData = JSON.parse(await fs.readFile(filePath, 'utf-8'));
              
              // Get employee ID from database
              const employeeId = file.replace('.json', '');
              const { data: employee } = await supabase
                .from('employees')
                .select('id')
                .eq('employee_id', employeeId)
                .single();

              if (!employee) {
                this.stats.errors.push(`Employee not found for payroll: ${employeeId}`);
                continue;
              }

              const { error } = await supabase
                .from('payroll_records')
                .insert({
                  employee_id: employee.id,
                  pay_period_start: payrollData.pay_period_start,
                  pay_period_end: payrollData.pay_period_end,
                  basic_salary: parseFloat(payrollData.basic_salary || 0),
                  overtime_pay: parseFloat(payrollData.overtime_pay || 0),
                  bonuses: parseFloat(payrollData.bonuses || 0),
                  deductions: parseFloat(payrollData.deductions || 0),
                  gross_pay: parseFloat(payrollData.gross_pay || 0),
                  tax_deduction: parseFloat(payrollData.tax_deduction || 0),
                  net_pay: parseFloat(payrollData.net_pay || 0),
                  payment_status: payrollData.payment_status || 'pending',
                  payment_date: payrollData.payment_date,
                  payment_method: payrollData.payment_method
                });

              if (error) {
                this.stats.errors.push(`Payroll migration error: ${error.message}`);
              } else {
                this.stats.payroll++;
              }
            }
          }
        }
      }
      
      console.log(`‚úÖ Migrated ${this.stats.payroll} payroll records`);
    } catch (error) {
      console.error('‚ùå Payroll migration failed:', error);
      this.stats.errors.push(`Payroll migration failed: ${error}`);
    }
  }

  private async migrateVehicles() {
    console.log('üöó Migrating vehicle data...');
    
    try {
      const vehiclesDir = path.join(process.cwd(), 'database/vehicles');
      const files = await fs.readdir(vehiclesDir);
      
      for (const file of files) {
        if (file.endsWith('.json')) {
          const filePath = path.join(vehiclesDir, file);
          const vehicle = JSON.parse(await fs.readFile(filePath, 'utf-8'));
          
          const { error } = await supabase
            .from('vehicles')
            .insert({
              registration_number: vehicle.registration_number || file.replace('.json', ''),
              make: vehicle.make,
              model: vehicle.model,
              year: vehicle.year ? parseInt(vehicle.year) : null,
              color: vehicle.color,
              engine_number: vehicle.engine_number,
              chassis_number: vehicle.chassis_number,
              purchase_price: vehicle.purchase_price ? parseFloat(vehicle.purchase_price) : null,
              purchase_date: vehicle.purchase_date,
              status: vehicle.status || 'available',
              current_owner: vehicle.current_owner,
              documents: vehicle.documents ? JSON.stringify(vehicle.documents) : null,
              maintenance_records: vehicle.maintenance_records ? JSON.stringify(vehicle.maintenance_records) : null
            });

          if (error) {
            this.stats.errors.push(`Vehicle migration error for ${file}: ${error.message}`);
          } else {
            this.stats.vehicles++;
          }
        }
      }
      
      console.log(`‚úÖ Migrated ${this.stats.vehicles} vehicles`);
    } catch (error) {
      console.error('‚ùå Vehicle migration failed:', error);
      this.stats.errors.push(`Vehicle migration failed: ${error}`);
    }
  }

  private async migratePurchaseData() {
    console.log('üõí Migrating purchase data...');
    
    try {
      const purchaseFile = path.join(process.cwd(), 'database/purchase/vehicles.json');
      const data = JSON.parse(await fs.readFile(purchaseFile, 'utf-8'));
      
      const purchases = Array.isArray(data) ? data : [data];
      let count = 0;
      
      for (const purchase of purchases) {
        // Find matching vehicle
        const { data: vehicle } = await supabase
          .from('vehicles')
          .select('id')
          .eq('registration_number', purchase.registration_number)
          .single();

        const { error } = await supabase
          .from('purchase_transactions')
          .insert({
            transaction_number: purchase.transaction_number || `PUR-${Date.now()}-${count}`,
            vehicle_id: vehicle?.id,
            supplier_name: purchase.supplier_name,
            supplier_contact: purchase.supplier_contact ? JSON.stringify(purchase.supplier_contact) : null,
            purchase_price: parseFloat(purchase.purchase_price || 0),
            purchase_date: purchase.purchase_date,
            payment_method: purchase.payment_method,
            payment_status: purchase.payment_status || 'pending',
            documents: purchase.documents ? JSON.stringify(purchase.documents) : null,
            notes: purchase.notes
          });

        if (error) {
          this.stats.errors.push(`Purchase migration error: ${error.message}`);
        } else {
          count++;
        }
      }
      
      console.log(`‚úÖ Migrated ${count} purchase records`);
    } catch (error) {
      console.error('‚ùå Purchase migration failed:', error);
      this.stats.errors.push(`Purchase migration failed: ${error}`);
    }
  }

  private async migrateSalesData() {
    console.log('üí∞ Migrating sales data...');
    // Similar implementation for sales data
    console.log('‚úÖ Sales data migration completed (implement based on existing data structure)');
  }

  private generateReport() {
    console.log('\n' + '='.repeat(60));
    console.log('üìä MIGRATION COMPLETE - SUMMARY REPORT');
    console.log('='.repeat(60));
    
    console.log(`‚úÖ Countries migrated: ${this.stats.countries}`);
    console.log(`‚úÖ Holidays migrated: ${this.stats.holidays}`);
    console.log(`‚úÖ Employees migrated: ${this.stats.employees}`);
    console.log(`‚úÖ Attendance records migrated: ${this.stats.attendance}`);
    console.log(`‚úÖ Payroll records migrated: ${this.stats.payroll}`);
    console.log(`‚úÖ Vehicles migrated: ${this.stats.vehicles}`);
    
    if (this.stats.errors.length > 0) {
      console.log(`\n‚ö†Ô∏è  Errors encountered: ${this.stats.errors.length}`);
      this.stats.errors.forEach((error, index) => {
        console.log(`${index + 1}. ${error}`);
      });
    }
    
    console.log('\nüéâ Migration completed successfully!');
    console.log('Next steps:');
    console.log('1. Update application code to use database queries');
    console.log('2. Test all functionality with new data structure');
    console.log('3. Archive or remove old JSON files after verification');
  }
}

// Run migration if called directly
if (require.main === module) {
  const migrator = new DataMigrator();
  migrator.runFullMigration()
    .then(() => {
      console.log('‚úÖ Migration script completed');
      process.exit(0);
    })
    .catch((error) => {
      console.error('‚ùå Migration script failed:', error);
      process.exit(1);
    });
}

export { DataMigrator };